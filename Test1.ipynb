{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark.sql.types import *\r\n",
        "account_name = \"synapsesafibdev01\"\r\n",
        "container_name = \"fib\"\r\n",
        "relative_path = \"\"\r\n",
        "adls_path = 'abfss://%s@%s.dfs.core.windows.net/%s' % (container_name, account_name, relative_path)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = spark.read.option('header', 'true') \\\r\n",
        "                .option('delimiter', ',') \\\r\n",
        "                .csv(adls_path + '/Book1.csv')"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.head(2)"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.write.option('header', 'true') \\\r\n",
        "                .option('delimiter', ',') \\\r\n",
        "                .csv(adls_path + '/Book21.csv')"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\r\n",
        "//create user [abc] from external provider\r\n",
        "//exec sp_addrolemember 'db_role', 'abc'\r\n",
        "\r\n",
        "\r\n",
        "val df = spark.read.\r\n",
        "option(Constants.SERVER, \"sql-fi6-dev.database.windows.net\").\r\n",
        "synapsesql(\"sqldw-fi6-dev.edl.ControlTableEDL\")\r\n",
        "\r\n",
        "df.printSchema\r\n",
        "\r\n",
        "df.createOrReplaceTempView(\"testview\")\r\n"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "scala"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\r\n",
        "select * from testview"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "sparksql"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To be able to complete this lab in under an hour, let's just work with 1,500k rows\r\n",
        "data_all = spark.sql(\"SELECT * FROM AdultCensusIncome4\").limit(15000000)\r\n",
        "#sample.createOrReplaceTempView(\"AdultCensusIncome\")\r\n",
        "\r\n",
        "columns_new = [col.replace(\"-\", \"\") for col in data_all.columns]\r\n",
        "data_all = data_all.toDF(*columns_new)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}